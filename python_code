####################loading required libraries#################################
import pandas as pd
import string
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
import numpy as np


data = open("C:/Users/karth/OneDrive/Desktop/test_txt.txt").read()
rawdata = data.replace('\t', '\n').split('\n')
label= rawdata[0::2]
text = rawdata[1::2]
df = pd.DataFrame({'label':label, 'text':text})
def nonpunc(text):
    nonpunc1 = "".join([word for word in text if word not in string.punctuation])
    return nonpunc1
df['nonpunc1'] = df['label'].apply(lambda x: nonpunc(x))

###########text to data using tf-idf###########################################

tfidf_transformer = TfidfTransformer()
X_train_tfidf = tfidf_transformer.fit_transform(xcounts)
X_train_tfidf.shape
tf_sparse1 = pd.DataFrame(X_train_tfidf.toarray())

##############creating pipeline for countvectorize, tf-idf,multinomialNB#####################################################

text_clf = Pipeline([('vect', CountVectorizer()),
                     ('tfidf', TfidfTransformer()),
                     ('clf', MultinomialNB())])
text_clf = text_clf.fit(df['nonpunc1_text'], df['nonpunc1'])
twenty_test = df(subset='test', shuffle=True)
x_train, x_test, y_train, y_test = train_test_split(df['nonpunc1_text'], df['nonpunc1'], test_size=0.2)

########using gridsearch optimisation#######################################################3

parameters = {'vect__ngram_range': [(1, 1), (1, 2)],
              'tfidf__use_idf': (True, False),
              'clf__alpha': (1e-2, 1e-3)}
gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)
gs_clf = gs_clf.fit(x_train, y_train
gs_clf.best_score_
